{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a714e10e",
   "metadata": {},
   "source": [
    "## Classical Flow Matching\n",
    "Implementing a classical flow matching model to compare to the quantum model, which ended up being diffusion/flow matching inspired.\n",
    "\n",
    "Heavily inspired by: [Flow Matching on MNIST](https://github.com/seichang00/flow-matching-lightning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208d5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\realc\\OneDrive\\Documents\\GSOC\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\realc\\OneDrive\\Documents\\GSOC\n"
     ]
    }
   ],
   "source": [
    "%cd C:/Users/realc/OneDrive/Documents/GSOC\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d16d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "out_dir = \"fm_outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "image_size = 28\n",
    "channels = 1\n",
    "latent_std = 1.0  # standard deviation for gaussian prior\n",
    "save_every = 10\n",
    "subset_size = 100  # Set to None to use full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10f887ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),               # 0-1\n",
    "    transforms.Normalize((0.5,), (0.5,)) # map to [-1, 1]\n",
    "])\n",
    "train_ds = datasets.MNIST(root=\"./mnist\", train=True, download=False, transform=transform)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=4)\n",
    "\n",
    "if subset_size is not None:\n",
    "    train_ds = torch.utils.data.Subset(train_ds, range(subset_size))\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf153b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(dim, dim*4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim*4, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        # sinusoidal embedding (like transformer / diffusion)\n",
    "        half = self.dim // 2\n",
    "        freqs = torch.exp(-math.log(10000) * torch.arange(0, half, device=t.device) / half)\n",
    "        args = t.unsqueeze(-1) * freqs.unsqueeze(0)  # (B, half)\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.lin(emb)\n",
    "    \n",
    "class SmallConvField(nn.Module):\n",
    "    def __init__(self, in_ch=1, base_ch=64, time_emb_dim=32):\n",
    "        super().__init__()\n",
    "        self.time_emb = TimeEmbedding(time_emb_dim)\n",
    "\n",
    "        self.init_conv = nn.Conv2d(in_ch + 1, base_ch, kernel_size=3, padding=1) # +1 channel for time broadcast\n",
    "        self.down1 = nn.Conv2d(base_ch, base_ch, kernel_size=3, padding=1)\n",
    "        self.down2 = nn.Conv2d(base_ch, base_ch, kernel_size=3, padding=1)\n",
    "\n",
    "        self.mid = nn.Sequential(\n",
    "            nn.Conv2d(base_ch, base_ch, kernel_size=3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, base_ch, kernel_size=3, padding=1),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        # inject time embedding to final layers via broadcasting and addition\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(base_ch, base_ch, kernel_size=3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(base_ch, in_ch, kernel_size=3, padding=1)  # predict same-channel vector field\n",
    "        )\n",
    "\n",
    "        self.time_proj = nn.Linear(time_emb_dim, base_ch)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        x: (B, C, H, W) where C=1 (image)\n",
    "        t: (B,) in [0,1]\n",
    "        returns v(x,t) shape same as x\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        # broadcast time as an extra channel (scalar per image)\n",
    "        t_channel = t.view(B, 1, 1, 1).expand(-1, 1, H, W)\n",
    "        xt = torch.cat([x, t_channel], dim=1)  # (B, C+1, H, W)\n",
    "        h = self.init_conv(xt)\n",
    "        h = F.silu(self.down1(h) + h)\n",
    "        h = F.silu(self.down2(h) + h)\n",
    "\n",
    "        h = self.mid(h)\n",
    "        # time embedding projection and add\n",
    "        t_emb = self.time_emb(t)             # (B, time_emb_dim)\n",
    "        t_proj = self.time_proj(t_emb)       # (B, base_ch)\n",
    "        t_proj = t_proj.view(B, -1, 1, 1)    # (B, base_ch, 1, 1)\n",
    "        h = h + t_proj\n",
    "\n",
    "        out = self.final(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3353a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_mix(x0, x1, t):\n",
    "    # x_t = (1 - t) * x0 + t * x1\n",
    "    return (1.0 - t.view(-1,1,1,1)) * x0 + t.view(-1,1,1,1) * x1\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch}\")\n",
    "    for imgs, _ in pbar:\n",
    "        imgs = imgs.to(device)  # x0: (B,1,28,28) in [-1,1]\n",
    "        B = imgs.shape[0]\n",
    "\n",
    "        # sample random prior images x1 ~ N(0, I)\n",
    "        x1 = torch.randn_like(imgs) * latent_std\n",
    "\n",
    "        # sample t uniformly in [0,1)\n",
    "        t = torch.rand(B, device=device)\n",
    "\n",
    "        # construct x_t\n",
    "        x_t = linear_mix(imgs, x1, t)\n",
    "\n",
    "        # target vector field: dx_t/dt = x1 - x0 (constant for linear interpolation)\n",
    "        target_v = (x1 - imgs)\n",
    "\n",
    "        # predict v(x_t, t)\n",
    "        pred_v = model(x_t, t)\n",
    "\n",
    "        loss = F.mse_loss(pred_v, target_v)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * B\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def rk4_integration(model, x_init, t0=1.0, t1=0.0, steps=50):\n",
    "    \"\"\"\n",
    "    Integrate dx/dt = v(x, t) from t0 -> t1 using RK4\n",
    "    x_init: (B, C, H, W) initial states at time t0\n",
    "    returns x_final at t1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = x_init.clone()\n",
    "    B = x.shape[0]\n",
    "    t0 = float(t0)\n",
    "    t1 = float(t1)\n",
    "    dt = (t1 - t0) / steps  # negative if t1 < t0\n",
    "\n",
    "    t = t0\n",
    "    for i in range(steps):\n",
    "        t_tensor = torch.full((B,), t, device=x.device)\n",
    "        k1 = model(x, t_tensor)\n",
    "        k2 = model(x + 0.5 * dt * k1, t_tensor + 0.5 * dt)\n",
    "        k3 = model(x + 0.5 * dt * k2, t_tensor + 0.5 * dt)\n",
    "        k4 = model(x + dt * k3, t_tensor + dt)\n",
    "        x = x + (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n",
    "        t = t + dt\n",
    "    return x\n",
    "\n",
    "def sample_and_save(model, epoch, n=64, steps=80):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n, channels, image_size, image_size, device=device) * latent_std  # sample from prior at t=1\n",
    "        x = rk4_integration(model, z, t0=1.0, t1=0.0, steps=steps)\n",
    "        # map back from [-1,1] to [0,1] for visualization\n",
    "        imgs = (x.clamp(-1,1) + 1.0) / 2.0\n",
    "        grid = utils.make_grid(imgs, nrow=int(math.sqrt(n)), pad_value=1.0)\n",
    "        save_path = os.path.join(out_dir, f\"samples_epoch_{epoch}.png\")\n",
    "        utils.save_image(grid, save_path)\n",
    "        print(f\"Saved samples to {save_path}\")\n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "238d9f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3/3 [00:07<00:00,  2.47s/it, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 1.681747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3/3 [00:07<00:00,  2.43s/it, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss: 1.364048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3/3 [00:07<00:00,  2.51s/it, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss: 1.321450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it, loss=1.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss: 1.298679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 average loss: 1.258291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 3/3 [00:10<00:00,  3.39s/it, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 average loss: 1.199826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 3/3 [00:10<00:00,  3.42s/it, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 average loss: 1.106845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 3/3 [00:10<00:00,  3.37s/it, loss=0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 average loss: 0.855801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 3/3 [00:07<00:00,  2.54s/it, loss=0.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 average loss: 1.161571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 3/3 [00:15<00:00,  5.03s/it, loss=0.934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 average loss: 0.881451\n",
      "Saved samples to fm_outputs\\samples_epoch_10.png\n",
      "Saved model checkpoint.\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "model = SmallConvField(in_ch=channels, base_ch=64, time_emb_dim=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, epoch)\n",
    "    print(f\"Epoch {epoch} average loss: {train_loss:.6f}\")\n",
    "\n",
    "    if epoch % save_every == 0 or epoch == epochs:\n",
    "        sample_and_save(model, epoch, n=64, steps=100)\n",
    "        torch.save(model.state_dict(), os.path.join(out_dir, f\"model_epoch_{epoch}.pth\"))\n",
    "        print(\"Saved model checkpoint.\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45643b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

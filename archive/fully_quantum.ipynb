{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Quantum Model\n",
    "The main model that uses Haar measure for the forward process and quantum layers for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.statistics import calculate_statistics, calculate_fid\n",
    "from utils.decoding import decode, flip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation using the partially preprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/masha/Documents/GSOC/GSoC-Quantum-Diffusion-Model\n",
    "\n",
    "from utils.post_training import *\n",
    "from utils.statistics import *\n",
    "from utils.plotting import *\n",
    "from utils.angle_encoding_script import angle_encoding\n",
    "from utils.haar_noising_script import apply_haar_scrambling\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.linalg\n",
    "\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QG_channel = 1\n",
    "filename = f\"data/QG{QG_channel}_normalized_16x16_100k\"\n",
    "data_X = np.array(h5py.File(filename, \"r\")['X'])\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "encoded_data_load = torch.load(f\"data/Q{QG_channel}_16x16_100k_encoded.pt\")\n",
    "print(encoded_data_load.shape)\n",
    "\n",
    "scrambled_states = apply_haar_scrambling(np.array(encoded_data_load), num_samples, seed=42)\n",
    "scrambled_states = torch.tensor(scrambled_states, dtype=torch.float32)\n",
    "print(scrambled_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing with non normalized or discretized images'''\n",
    "QG_channel = 1\n",
    "filename = f\"data/QG{QG_channel}_16x16_1k\"\n",
    "data_X = np.array(h5py.File(filename, \"r\")['X'])\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "encoded_data = [angle_encoding(data_X, sample) for sample in range(num_samples)]\n",
    "encoded_data = torch.tensor(np.array(encoded_data), dtype=torch.float32)\n",
    "print(encoded_data.shape)\n",
    "\n",
    "scrambled_states = apply_haar_scrambling(np.array(encoded_data), num_samples, seed=42)\n",
    "scrambled_states = torch.tensor(scrambled_states, dtype=torch.float32)\n",
    "print(scrambled_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the fully quantum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoded_data_load\n",
    "\n",
    "train_encoded_data, val_encoded_data, train_scrambled_states, val_scrambled_states = train_test_split(\n",
    "    encoded_data[:num_samples], scrambled_states, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "n_qubits = 8\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_circuit(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
    "        self.qlayer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.qlayer(x)\n",
    "\n",
    "class QuantumDiffusionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_qubits, n_layers):\n",
    "        super(QuantumDiffusionModel, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.num_patches = input_dim // n_qubits\n",
    "        \n",
    "        self.quantum_layer = QuantumLayer(n_qubits, n_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_patched = x.view(-1, self.num_patches, self.n_qubits)  # [batch_size, num_patches, n_qubits]\n",
    "\n",
    "        output_patches = []\n",
    "        for patch in range(self.num_patches):\n",
    "            patch_out = self.quantum_layer(x_patched[:, patch])\n",
    "            output_patches.append(patch_out)\n",
    "        \n",
    "        x = torch.cat(output_patches, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 8\n",
    "input_dim = 8 * 8 * 4\n",
    "hidden_dim = 128\n",
    "output_dim = input_dim  \n",
    "\n",
    "model = QuantumDiffusionModel(input_dim, hidden_dim, output_dim, n_qubits, n_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "loss_values = []\n",
    "val_loss_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_scrambled_states.view(len(train_scrambled_states), -1))\n",
    "    loss = criterion(outputs, train_encoded_data.view(len(train_encoded_data), -1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(val_scrambled_states.view(len(val_scrambled_states), -1))\n",
    "        val_loss = criterion(val_outputs, val_encoded_data.view(len(val_encoded_data), -1))\n",
    "        val_loss_values.append(val_loss.item())\n",
    "        \n",
    "        denoised_states = model(val_scrambled_states.view(len(val_scrambled_states), -1))\n",
    "        denoised_states = denoised_states.view(len(val_scrambled_states), 8, 8, 4).detach().numpy()\n",
    "        decoded_data = decode(denoised_states)\n",
    "        decoded_data = flip(decoded_data)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(loss_values, label='Training Loss', color='blue')\n",
    "plt.plot(val_loss_values, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = f\"fq_{num_epochs}e_{num_samples}s_{n_qubits}q_{n_layers}l\"\n",
    "torch.save(model.state_dict(), saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-training model loading, analysis, and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantumDiffusionModel(input_dim, hidden_dim, output_dim, n_qubits, n_layers)\n",
    "model.load_state_dict(torch.load(saved_model_path, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_to_generate = 10\n",
    "new_images = generate_new_images(model, num_samples_to_generate)\n",
    "plot_all_decoded_images(new_images)\n",
    "# plot_mean_decoded_images(new_images)\n",
    "# plot_all_decoded_images(new_images, grid_size=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = new_images\n",
    "\n",
    "real_data = data_X[:len(generated_data)]\n",
    "\n",
    "mu_real, sigma_real = calculate_statistics(real_data)\n",
    "mu_gen, sigma_gen = calculate_statistics(flip(generated_data))\n",
    "fid = calculate_fid(mu_real, sigma_real, mu_gen, sigma_gen)\n",
    "print(\"FID \", fid)\n",
    "\n",
    "wasserstein_value = calculate_wasserstein(real_data, flip(generated_data))\n",
    "print(\"Wasserstein 1 \", wasserstein_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_images = plot_decoded_images_without_noise(new_images, grid_size=(10, 10), threshold_percent=99.61)\n",
    "\n",
    "limit = 10\n",
    "real_data = real_data[:limit]\n",
    "denoised_images = denoised_images[:limit]\n",
    "mu_real, sigma_real = calculate_statistics(real_data)\n",
    "mu_gen, sigma_gen = calculate_statistics(denoised_images)\n",
    "fid = calculate_fid(mu_real, sigma_real, mu_gen, sigma_gen)\n",
    "print(\"FID \", fid)\n",
    "\n",
    "mu_real, sigma_real = calculate_statistics(real_data)\n",
    "mu_gen, sigma_gen = calculate_statistics(denoised_images)\n",
    "fid = calculate_fid_stable(mu_real, sigma_real, mu_gen, sigma_gen)\n",
    "print(\"Stable FID:\", fid)\n",
    "\n",
    "wasserstein_value = calculate_wasserstein(real_data, denoised_images)\n",
    "print(\"Wasserstein 1 \", wasserstein_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = \"1\"\n",
    "exponent = \"10000011\"\n",
    "mantissa = \"00100111010001001000101\"\n",
    "exponent = int(exponent, 2) - 127 # compensate for bias\n",
    "mantissa = 1.0 + int(mantissa, 2) / 2 ** len(mantissa) # convert to 1.xxxx format\n",
    "print(\"exponent (decimal, including bias)\", exponent)\n",
    "print(\"mantissa (decimal, including leading 1)\", mantissa)\n",
    "if sign == \"1\":\n",
    "    number = -1 * mantissa * 2 ** exponent\n",
    "else:\n",
    "    number = mantissa * 2 ** exponent\n",
    "print(\"number\", number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
